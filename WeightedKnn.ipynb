{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "#reading the csv file\n",
    "df = pd.read_csv(r'C:\\Users\\khushalpt\\data.csv')\n",
    "\n",
    "\n",
    "\n",
    "#function to calculate the euclidean distance of the continuous value\n",
    "def euclideanDistance_Calc(field1, field2, length):\n",
    "    dist_mat = 0\n",
    "    for x in range(length - 1):        \n",
    "        dist_mat+= pow((field1[x] - field2[x]),2)\n",
    "        w = math.sqrt(dist_mat)\n",
    "    return (w)\n",
    "\n",
    "#function to calculate the manhattan distance of 2nd continuous value\n",
    "def manhattanDistance_Calc(field1, field2, length):\n",
    "    manhattanDist = 0\n",
    "    for x in range(length - 1):        \n",
    "        manhattanDist+= abs(field1[x+1] - field2[x+1])\n",
    "        w = manhattanDist\n",
    "    return (w)\n",
    "\n",
    "\n",
    "#normalisation technique for zscore \n",
    "\n",
    "def zscore(a)\n",
    "    df[\"petal_length\"] = (df[\"petal_length\"]-df.[\"petal_length\"].mean())/df.[\"petal_length\"].std()\n",
    "\n",
    "#normalisation technique for min max\n",
    "\n",
    "def minmax()\n",
    "    df[\"petal_width\"] = (df[\"petal_width\"]-df[\"petal_width\"].min())/(df[\"petal_width\"].max()-df[\"petal_width\"].min())\n",
    "    \n",
    "\n",
    "#Label encoding to convert categorical values to continuous\n",
    "obj_df[\"class\"] = obj_df[\"class\"].astype('category')\n",
    "obj_df.dtypes\n",
    "obj_df[\"class_cat\"] = obj_df[\"class\"].cat.codes\n",
    "#obj_df.head() \n",
    "    \n",
    "#Calculating distance for categorical after converting it to continuous\n",
    "def euclideanDistance_Calc_Categorical(field1_cat, field2_cat, length_cat):\n",
    "    dist_mat_cat = 0\n",
    "    for x in range(length - 1):        \n",
    "        dist_mat_cat+= pow((field1_cat[x+1] - field2_cat[x+1]),2)\n",
    "        w = math.sqrt(dist_mat_cat)\n",
    "    return (w)\n",
    "\n",
    "\n",
    "#Neighbor generation using training and test instances\n",
    "def getNeighbours(trainingData, testInstance, k):\n",
    "    distant = []\n",
    "    length = len(testInstance)-1\n",
    "    for x in range(len(trainingData)):\n",
    "    #get euclidean distance to calculate neighbors\n",
    "        dist=euclideanDistance_Calc(list(testInstance), list(trainingData.iloc[x,:]), length) \n",
    "        distant.append((trainingData.iloc[x,:],dist))\n",
    "    distant.sort(key=operator.itemgetter(1))\n",
    "    neigh = []\n",
    "    for i in range(k):\n",
    "        neigh.append(distant[i][0])\n",
    "        #print(neigh)\n",
    "    return neigh\n",
    "\n",
    "#Predicting the response of the neighbors. Each neighbor votes for the class attribute and the majority is predicted\n",
    "def getPredictions(neighs):\n",
    "    classVotes={} #assuming class is the last attribute for each neighbor\n",
    "    for w in range(len(neighs)):\n",
    "        res = neighs[w][-1]\n",
    "        if response in classVotes:\n",
    "            classVotes[response] += 1\n",
    "        else:\n",
    "            classVotes[response] = 1\n",
    "    sortedVotes = sorted(classVotes.items(),key = operator.itemgetter(1), reverse=True)\n",
    "    return sortedVotes[0][0]\n",
    "\n",
    "#Accuracy is tested taking teh test set and the predicted values \n",
    "def accFunction(tested, predictions):\n",
    "    correctedPred = 0\n",
    "    for x in range(len(tested)):\n",
    "    #ratio of the total correct predictions out of all prediction made\n",
    "        if tested[x][-1] is predictions[x]:\n",
    "            correctedPred += 1\n",
    "    return (correctedPred/float(len(tested))) * 100.00\n",
    "\n",
    "\n",
    "To measure the distance of weights with the votes of every feature\n",
    "def vote_distance_weights(neighs, all_results=True):\n",
    "    class_votes = Counter()\n",
    "    number_of_neighbors = len(neighs)\n",
    "    for index in range(number_of_neighbors):\n",
    "        dist = neighs[index][1]\n",
    "        label = neighs[index][2]\n",
    "        class_votes[label] += 1 / (dist**2 + 1)\n",
    "    labels, votes = zip(*class_counter.most_common())\n",
    "    #print(labels, votes)\n",
    "    winner = class_votes.most_common(1)[0][0]\n",
    "    votes4winner = class_counter.most_common(1)[0][1]\n",
    "    if all_results:\n",
    "        total = sum(class_counter.values(), 0.0)\n",
    "        for key in class_counter:\n",
    "             class_counter[key] /= total\n",
    "        return winner, class_votes.most_common()\n",
    "    else:\n",
    "        return winner, votes4winner / sum(votes)\n",
    "\n",
    "#Getting weights to develop weighted knn\n",
    "\n",
    "def make_weights(k, distances):\n",
    "  result = np.zeros(k, dtype=np.float32)\n",
    "  sum = 0.0\n",
    "  for i in range(k):\n",
    "    result[i] += 1.0 / distances[i] #formulate the function to procure the weights\n",
    "    sum += result[i]\n",
    "  result /= sum\n",
    "  return result\n",
    "# main function to execute the code taking in the percentage for imputation and value for k\n",
    "def weighted_knn(percentage,k,col):\n",
    "    per=0\n",
    "    df1 = df.iloc[:,0].copy()\n",
    "    per = round(((len(df1))*percentage)/100) #to calclate percentage of missingness\n",
    "    df1n = df1.sample(per) #creating missing values\n",
    "    li = []\n",
    "    l1 = list(df1n.index.values.tolist())\n",
    "    print(l1)\n",
    "    k=1\n",
    "    for i in l1:\n",
    "        df.iloc[i,0] = np.nan\n",
    "   \n",
    "    print(df)\n",
    "    test = df.iloc[l1].copy()\n",
    "    testing_data = test.drop(test.columns[col], axis=1)\n",
    "    print(testing_data)\n",
    "   \n",
    "    tt = df.copy()\n",
    "    trainingData = tt.drop(l1)\n",
    "    print(trainingData)\n",
    "   \n",
    "    trainingDist = trainingData.copy()\n",
    "    trainingDist = trainingdist.drop(trainingDist.columns[col], axis=1)\n",
    "    print(trainingDist)\n",
    "   \n",
    "    for y in range(len(testing_data)):\n",
    "        neighbor_list = getNeighbours(trainingData,trainingDist,testing_data.iloc[y],k)\n",
    "        #print(neighbor_list)  \n",
    "        result = Fetchpredictions(neighbor_list)\n",
    "        predictions.append(result)\n",
    "        #print(predictions)\n",
    "#     accuracy = accuracytest(list(testing_data), list(predictions))\n",
    "#     print('Accuracy for neighbor: ' + repr(accuracy) + '%')\n",
    "        print(neighbor_list) \n",
    "        print(\"index: \", i, \n",
    "          \", result of vote: \", vote_distance_weights(neighbor_list,\n",
    "                                                      all_results=True)) \n",
    "\n",
    "weighted_knn(5,1,0)\n",
    "#percentage can be changed to 10 and 20 and also the K value can be changed dynamically to 5 or 7 instead of 1\n",
    "\n",
    "weighted_knn(10,1,0)\n",
    "weighted_knn(20,1,0)\n",
    "\n",
    "weighted_knn(5,7,0)\n",
    "weighted_knn(10,7,0)\n",
    "weighted_knn(20,7,0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
